{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('./hull-tactical-market-prediction/train.csv')\n",
    "test_data = pd.read_csv('./hull-tactical-market-prediction/test.csv')\n",
    "\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"\\nTrain data columns:\", train_data.columns.tolist())\n",
    "print(\"\\nFirst few rows of train data:\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in train data:\")\n",
    "print(train_data.isnull().sum().sum())\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(test_data.isnull().sum().sum())\n",
    "\n",
    "# Display target variable statistics\n",
    "print(\"\\n=== Target Variable Statistics ===\")\n",
    "print(train_data['market_forward_excess_returns'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "# Define feature groups based on column prefixes\n",
    "feature_prefixes = ['D', 'E', 'I', 'M', 'P', 'S', 'V']\n",
    "\n",
    "# Get all feature columns\n",
    "feature_cols = [col for col in train_data.columns \n",
    "                if any(col.startswith(prefix) for prefix in feature_prefixes)]\n",
    "\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "\n",
    "# Target variable\n",
    "target_col = 'market_forward_excess_returns'\n",
    "\n",
    "# Separate features and target for training data\n",
    "X_train_full = train_data[feature_cols].copy()\n",
    "y_train_full = train_data[target_col]\n",
    "\n",
    "# Check which features have too many missing values\n",
    "missing_pct = X_train_full.isnull().sum() / len(X_train_full) * 100\n",
    "print(f\"\\nFeatures with >50% missing values: {(missing_pct > 50).sum()}\")\n",
    "print(f\"Features with <50% missing values: {(missing_pct <= 50).sum()}\")\n",
    "\n",
    "# Use median imputation for features with some data, 0 for mostly empty features\n",
    "for col in feature_cols:\n",
    "    if missing_pct[col] > 90:\n",
    "        X_train_full[col].fillna(0, inplace=True)\n",
    "    else:\n",
    "        median_val = X_train_full[col].median()\n",
    "        X_train_full[col].fillna(median_val if not pd.isna(median_val) else 0, inplace=True)\n",
    "\n",
    "print(f\"\\nX_train shape: {X_train_full.shape}\")\n",
    "print(f\"y_train shape: {y_train_full.shape}\")\n",
    "print(f\"Remaining missing values: {X_train_full.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model\n",
    "print(\"Training XGBoost model...\")\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 1000,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'reg_alpha': 0.01,\n",
    "    'reg_lambda': 1.0,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor(**xgb_params)\n",
    "\n",
    "# Train with evaluation\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "print(f\"\\nModel training completed!\")\n",
    "print(f\"Number of boosting rounds: {model.n_estimators}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on validation set\n",
    "y_pred_val = model.predict(X_val)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred_val)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_val, y_pred_val)\n",
    "r2 = r2_score(y_val, y_pred_val)\n",
    "\n",
    "print(\"=== Validation Set Performance ===\")\n",
    "print(f\"MSE: {mse:.6f}\")\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"MAE: {mae:.6f}\")\n",
    "print(f\"RÂ² Score: {r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(20)\n",
    "\n",
    "plt.barh(importance_df['feature'], importance_df['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_val, y_pred_val, alpha=0.5)\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Market Forward Excess Returns')\n",
    "plt.ylabel('Predicted Market Forward Excess Returns')\n",
    "plt.title('Actual vs Predicted Returns (Validation Set)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "# Filter only rows that need to be scored\n",
    "test_scored = test_data[test_data['is_scored'] == True].copy()\n",
    "\n",
    "print(f\"Number of test samples to score: {len(test_scored)}\")\n",
    "\n",
    "# Prepare test features with same imputation strategy\n",
    "X_test = test_scored[feature_cols].copy()\n",
    "\n",
    "for col in feature_cols:\n",
    "    if missing_pct[col] > 90:\n",
    "        X_test[col].fillna(0, inplace=True)\n",
    "    else:\n",
    "        # Use training median for consistency\n",
    "        train_median = X_train_full[col].median()\n",
    "        X_test[col].fillna(train_median if not pd.isna(train_median) else 0, inplace=True)\n",
    "\n",
    "print(f\"Test missing values after imputation: {X_test.isnull().sum().sum()}\")\n",
    "\n",
    "# Make predictions\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Add predictions to test dataframe\n",
    "test_scored['predicted_market_forward_excess_returns'] = test_predictions\n",
    "\n",
    "print(\"\\nTest predictions summary:\")\n",
    "print(pd.Series(test_predictions).describe())\n",
    "\n",
    "# Display first few predictions\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "test_scored[['date_id', 'predicted_market_forward_excess_returns']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_scored' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save predictions to CSV for submission\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m submission = \u001b[43mtest_scored\u001b[49m[[\u001b[33m'\u001b[39m\u001b[33mdate_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpredicted_market_forward_excess_returns\u001b[39m\u001b[33m'\u001b[39m]].copy()\n\u001b[32m      3\u001b[39m submission.columns = [\u001b[33m'\u001b[39m\u001b[33mdate_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmarket_forward_excess_returns\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m submission.to_csv(\u001b[33m'\u001b[39m\u001b[33msubmission.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_scored' is not defined"
     ]
    }
   ],
   "source": [
    "# Save predictions to CSV for submission\n",
    "submission = test_scored[['date_id', 'predicted_market_forward_excess_returns']].copy()\n",
    "submission.columns = ['date_id', 'market_forward_excess_returns']\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to submission.csv\")\n",
    "print(f\"\\nSubmission file shape: {submission.shape}\")\n",
    "submission.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
